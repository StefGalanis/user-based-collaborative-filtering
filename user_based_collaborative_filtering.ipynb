{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ανοίγω το αρχείο κάνω mapping και ταυτόχρονα γεμίζω τα διανύσματα που θα χρησιμοποιήσω για να φτιάξω τον sparse πίνακα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratingsFile = open('pruned_data.csv',encoding = 'utf8',errors='ignore')\n",
    "users = {}\n",
    "business = {}\n",
    "user_counter = 0\n",
    "business_counter = 0\n",
    "row = []\n",
    "col = []\n",
    "data = []\n",
    "for line in ratingsFile:\n",
    "    lineValues = line.split(',')\n",
    "    user_id = lineValues[0]\n",
    "    business_id = lineValues[1]\n",
    "    rating = float(lineValues[2])\n",
    "    data.append(rating)\n",
    "    if user_id not in users:\n",
    "        row.append(user_counter)\n",
    "        users[user_id] = user_counter\n",
    "        user_counter += 1\n",
    "    else:\n",
    "        row_number = users[user_id]\n",
    "        row.append(row_number)\n",
    "    if business_id not in business:\n",
    "        col.append(business_counter)\n",
    "        business[business_id] = business_counter\n",
    "        business_counter += 1\n",
    "    else:\n",
    "        col_number = business[business_id]\n",
    "        col.append(col_number)\n",
    "ratingsFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δημιουργώ τον sparse πίνακα με βάση τα row col και data διανύσματα που έβγαλα από το αρχείο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp_sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row = np.array(row)\n",
    "col = np.array(col)\n",
    "data = np.array(data)\n",
    "M = sp_sparse.csr_matrix((data,(row,col)),shape=(len(users),len(business)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Διαλέγω τυχαία 5% του συνόλου των μη μηδενικών μετρήσεων και αφαιρώ μη μηδενικά κελιά του πίνακα μηδενίζοντας τα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "non_zero_cells = csr_matrix.nonzero(M)\n",
    "removed_cells = []\n",
    "removed_cells_sp = sp_sparse.lil_matrix((len(users),len(business)),dtype=float)\n",
    "num_non_zero = len(non_zero_cells[0])\n",
    "cells_to_remove = int(0.05*len(non_zero_cells[0]))\n",
    "while cells_to_remove > 0:\n",
    "    k = random.randint(0,num_non_zero-1)\n",
    "    i = non_zero_cells[0][k]\n",
    "    j = non_zero_cells[1][k]\n",
    "    if (i,j) not in removed_cells:\n",
    "        removed_cells.append((non_zero_cells[0][i],non_zero_cells[1][i],M[i,j]))\n",
    "        removed_cells_sp[i,j] = M[i,j]\n",
    "        M[i,j] = 0\n",
    "        cells_to_remove -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9855\n"
     ]
    }
   ],
   "source": [
    "print(len(removed_cells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4794, 4794)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "M_cosine_similarity = metrics.pairwise.cosine_similarity(M)\n",
    "print(M_cosine_similarity.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Εδώ θέτω αρχικά την διαγώνιο του πίνακα με τα similarities με 0 ώστε να μην επιρεάζει στην εντοπισμό των K πιο όμοιων χρηστών.\n",
    "* Για κάθε κελί που έχω διαγράψει τη βαθμολογία βάση της θέσης του στον πίνακα κάνω πρόβλεψη.\n",
    "* Κοιτάω σε ποιον χρήστη αντιστοιχεί η βαθμολογία.\n",
    "* Για τον χρήστη αυτό παίρνω την αντίστοιχη γραμμή του στον πίνακα με τα similarities με τους άλλου χρήστες.\n",
    "* Κοιτάω να δω σε ποιά επιχειρήση-column ανοίκει η βαθμολογία.\n",
    "* Για την επιχειρήση αυτή παίρνω όλη τη στήλη που της αντιστοιχεί(j) από τον πίνακα reviews(M) και κρατάω τις θέσεις των χρηστών που έχουν δώσει μη μηδενική βαθμολογία.\n",
    "* Τραβάω το index από την γραμμή με τα similarities του πιο όμοιου χρήστη (argmax).\n",
    "* Αν ανοίκει στη λίστα με τους χρήστες που έχουν δώσει μη μηδενική βαθμολογία προστίθεται στο σύνολο με τους Κ πιο όμοιους χρήστες.\n",
    "* Αλλιώς το similarity του είναι αδιάφορο το μηδενίζουμε και το αγνοούμε.\n",
    "* Αντλούμε έγκυρα argmax μέχρι να συγκεντρώσουμε τους K πιο όμοιους χρήστες.\n",
    "* Υπολογίζουμε τις προβλέψεις με βάση το σύνολο τον πιο όμοιων χρηστών και τις τοποθετούμε στον πίνακα με τα reviews.\n",
    "* Οι χρόνοι εκτέλεσεις δεν είναι ικανοποιοιτικοί ίσως χρειάζεται να τροποποιήσω τον αλγόριθμο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from scipy.sparse import csc_matrix,lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def user_based(M,K,M_cosine_similarity,removed_cells):\n",
    "    M_csc = csr_matrix.tocsc(M)\n",
    "    np.fill_diagonal(M_cosine_similarity,0)\n",
    "    predictions = []\n",
    "    predictions_sp = sp_sparse.lil_matrix((len(users),len(business)),dtype=float)\n",
    "    cell_counter = 0\n",
    "    start_time = time.time()\n",
    "    for removed_cell in removed_cells:\n",
    "\n",
    "        #Με j είναι οι χρήστρες και i είναι οι επιχειρήσεις\n",
    "        i = removed_cell[0]\n",
    "        j = removed_cell[1]\n",
    "\n",
    "        #αριθμός όμοιων επιχειρήσεων που θα συμβάλουν στον υπολογισμό πρόβλεψης της βαθμολογίας που θα έβαζε ο j χρήστης\n",
    "        k=K\n",
    "\n",
    "        #Εξάγω τις θέσεις των κελιών όπου άλλοι χρήστες έχουν δώσει βαθμολογία για την j επιχείρηση\n",
    "        non_zero_ratings = csc_matrix.nonzero(M_csc[:,j])\n",
    "        number = len(non_zero_ratings[0])\n",
    "\n",
    "        #Αυτή η μάσκα έχει άσους στις θέσεις όπου τα ratings για την επιχείρηση είναι μη μηδενικά\n",
    "        mask_data = np.ones((number))\n",
    "        mask_row = np.zeros((number),dtype=int)\n",
    "        mask_col = non_zero_ratings[0]\n",
    "        mask = sp_sparse.csr_matrix((mask_data,(mask_row,mask_col)),shape=(1,len(M_cosine_similarity[i,:])))\n",
    "\n",
    "        #Εδώ κρατάμε ένα slice με το similarity του χρήστη που μας ενδιαφέρει\n",
    "        similarity_row = M_cosine_similarity[i,:]\n",
    "        similarity_row = sp_sparse.csr_matrix(similarity_row)\n",
    "\n",
    "        similarity_row = similarity_row.toarray()\n",
    "        mask = mask.toarray()\n",
    "\n",
    "        result = similarity_row * mask\n",
    "        #φτιάχνω μια νέα μάσκα στην οποία πια θα κρατήσω μόνο τις K μεγαλύτερες όμοιότητες\n",
    "        new_mask = lil_matrix((1,len(M_cosine_similarity[i,:])), dtype=float)\n",
    "        \n",
    "        #φτιάχνω ένα αντίγραφο του πίνακα με τα συνολικά similarities για να έχω πρόσβαση στις πληροφορίες του πίνακα μετά την τροποποίηση του\n",
    "        #λόγω της διαδικασίας αναζήτησης των Κ κορυφαίων ομοιοτήτων μέσα στον πίνακα\n",
    "        copied = copy.deepcopy(result)\n",
    "\n",
    "        number_of_non_zero_similarities = len(non_zero_ratings[0])\n",
    "        if k > number_of_non_zero_similarities:\n",
    "            k = number_of_non_zero_similarities\n",
    "\n",
    "        while k > 0:\n",
    "            index = np.argmax(result)\n",
    "            #τοποθετώ το max similarity στο νέο κενό πίνακα που θα χρησιμοποιήσω για τον υπολογισμό της πρόβλεψης της βαθμολογίας\n",
    "            new_mask[0,index] = copied.item(0,index)\n",
    "\n",
    "            #θέτω 0 το max similarity που βρήκα για να πάρω με το argmax την θέση του αμέσως μεγαλύτερου από αυτό\n",
    "            result[0][index] = 0\n",
    "            k -= 1\n",
    "\n",
    "        sum_of_sim = 0\n",
    "        sum_of_rating = 0\n",
    "        #υπολογίζω το άθροισμα του παρονομαστή\n",
    "        sum_of_sim = np.sum(new_mask)\n",
    "\n",
    "        #υπολογίζω το άθροισμα του αριθμητή\n",
    "        sum_of_rating = new_mask * M[:,j]\n",
    "        sum_of_rating = np.sum(sum_of_rating)\n",
    "        cell_counter += 1\n",
    "\n",
    "        #καταχωρώ την πρόβλεψη στον πίνακα με τα predictions\n",
    "        if sum_of_sim != 0:\n",
    "            prediction = sum_of_rating/sum_of_sim\n",
    "        else:\n",
    "            prediction = 0\n",
    "        predictions_sp[i,j] = prediction\n",
    "        \n",
    "\n",
    "    end_time = time.time()\n",
    "    print(end_time-start_time)\n",
    "\n",
    "    return predictions_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse.linalg as sp_linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_predictions(M,k,removed_cells):\n",
    "    U,s,V = sp_linalg.svds(M,k,which = 'LM')\n",
    "    S = np.diag(s)\n",
    "    reconstructed_M = U[:,k:].dot(S[k:,k:]).dot(V[k:,:])\n",
    "    predictions_sp = sp_sparse.lil_matrix((len(users),len(business)),dtype=float)\n",
    "    for removed_cell in removed_cells:\n",
    "        i = removed_cell[0]\n",
    "        j = removed_cell[1]\n",
    "        predictions_sp[i,j] = reconstructed_M[i,j]\n",
    "    return predictions_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08365554187070667\n"
     ]
    }
   ],
   "source": [
    "predictions = user_based(M,5,M_cosine_similarity,removed_cells)\n",
    "RMSE_UBCF = sqrt(metrics.mean_squared_error(removed_cells_sp.toarray(), predictions.toarray()))\n",
    "print(RMSE_UBCF)\n",
    "prediction_matrix_svd = svd_predictions(M,5,removed_cells)\n",
    "RMSE_svd = sqrt(metrics.mean_squared_error(removed_cells_sp.toarray(), prediction_matrix_svd.toarray()))\n",
    "print(RMSE_svd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
